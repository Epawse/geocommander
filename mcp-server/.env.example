# GeoCommander MCP Server 环境变量配置
# 复制此文件为 .env 并填入你的配置

# ============ LLM 开关 ============
# 是否启用 LLM 解析（true/false）
# 如果为 false，将使用规则匹配作为备用
USE_LLM=true

# ============ Ollama（本地部署，推荐） ============
# Ollama 无需 API Key，只需本地运行 ollama serve
# 安装: curl -fsSL https://ollama.com/install.sh | sh
# 下载模型: ollama pull qwen2.5:7b
OLLAMA_BASE_URL=http://localhost:11434/v1
OLLAMA_MODEL=qwen2.5:7b

# ============ 阿里云百炼（推荐国内用户） ============
# 获取 API Key: https://bailian.console.aliyun.com/?tab=model#/api-key
# DASHSCOPE_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
# DASHSCOPE_MODEL=qwen-plus

# ============ 硅基流动 ============
# 获取 API Key: https://cloud.siliconflow.cn/
# SILICONFLOW_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
# SILICONFLOW_MODEL=Qwen/Qwen2.5-7B-Instruct

# ============ DeepSeek ============
# 获取 API Key: https://platform.deepseek.com/
# DEEPSEEK_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
# DEEPSEEK_MODEL=deepseek-chat

# ============ OpenAI ============
# 获取 API Key: https://platform.openai.com/api-keys
# 注意：中国大陆无法直接访问，需要代理
# OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
# OPENAI_BASE_URL=https://api.openai.com/v1
# OPENAI_MODEL=gpt-4o-mini

# ============ Google Vertex AI (Gemini) ============
# 支持两种配置方式：

# 方式1: JSON 文件（传统方式）
# GOOGLE_APPLICATION_CREDENTIALS=/path/to/your-service-account.json

# 方式2: 直接填写（Cherry Studio 风格，推荐）
# 从 Google Cloud Console 下载的 JSON 密钥文件中获取以下信息：
# VERTEX_CLIENT_EMAIL=your-service-account@project.iam.gserviceaccount.com
# VERTEX_PRIVATE_KEY=-----BEGIN PRIVATE KEY-----\n...\n-----END PRIVATE KEY-----\n
# VERTEX_PROJECT_ID=your-gcp-project-id
# VERTEX_LOCATION=us-central1
# VERTEX_MODEL=gemini-2.5-flash-lite

# ============ 自定义 OpenAI 兼容服务 ============
# 任何兼容 OpenAI API 的服务都可以使用
# LLM_API_KEY=your-api-key
# LLM_BASE_URL=https://your-api-endpoint/v1
# LLM_MODEL=your-model-name

# ============ 服务商优先级 ============
# 系统会按以下顺序选择第一个可用的服务商：
# 1. custom（自定义）
# 2. vertex_ai（Google Gemini）
# 3. dashscope（阿里云百炼）
# 4. siliconflow（硅基流动）
# 5. deepseek
# 6. openai
# 7. ollama（本地）
